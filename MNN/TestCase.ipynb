{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "开始\n",
      "开始训练------\n",
      "开始训练模型---------\n",
      "训练模型完毕\n",
      "1_Epoch:  1 | test loss: 1.3832 | test accuracy: 0.5228\n",
      "开始训练模型---------\n",
      "训练模型完毕\n",
      "1_Epoch:  2 | test loss: 0.7394 | test accuracy: 0.7632\n",
      "开始训练模型---------\n",
      "训练模型完毕\n",
      "1_Epoch:  3 | test loss: 0.6138 | test accuracy: 0.8009\n",
      "开始训练模型---------\n",
      "训练模型完毕\n",
      "1_Epoch:  4 | test loss: 0.6249 | test accuracy: 0.8035\n",
      "开始训练模型---------\n",
      "训练模型完毕\n",
      "1_Epoch:  5 | test loss: 0.6196 | test accuracy: 0.8026\n",
      "开始训练模型---------\n",
      "训练模型完毕\n",
      "1_Epoch:  6 | test loss: 0.5882 | test accuracy: 0.7947\n",
      "开始训练模型---------\n",
      "训练模型完毕\n",
      "1_Epoch:  7 | test loss: 0.5694 | test accuracy: 0.8140\n",
      "开始训练模型---------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Software\\Anaconda\\envs\\pytorch_gpu\\lib\\site-packages\\ipykernel_launcher.py:107: H5pyDeprecationWarning: dataset.value has been deprecated. Use dataset[()] instead.\n",
      "D:\\Software\\Anaconda\\envs\\pytorch_gpu\\lib\\site-packages\\ipykernel_launcher.py:108: H5pyDeprecationWarning: dataset.value has been deprecated. Use dataset[()] instead.\n",
      "D:\\Software\\Anaconda\\envs\\pytorch_gpu\\lib\\site-packages\\ipykernel_launcher.py:111: H5pyDeprecationWarning: dataset.value has been deprecated. Use dataset[()] instead.\n",
      "D:\\Software\\Anaconda\\envs\\pytorch_gpu\\lib\\site-packages\\ipykernel_launcher.py:112: H5pyDeprecationWarning: dataset.value has been deprecated. Use dataset[()] instead.\n",
      "D:\\Software\\Anaconda\\envs\\pytorch_gpu\\lib\\site-packages\\ipykernel_launcher.py:237: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    }
   ],
   "source": [
    "import  os\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as Data\n",
    "from sklearn.model_selection import train_test_split\n",
    "from MNN import *\n",
    "import pyedflib\n",
    "import numpy as np\n",
    "import h5py\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix as cm\n",
    "import  matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "import gc\n",
    "from ResultCode import cm_plot,kappa\n",
    "from copy import deepcopy\n",
    "\n",
    "##迭代次数为50\n",
    "EPOCH = 50\n",
    "# batch size 为128\n",
    "BATCH_SIZE = 128\n",
    "##学习率为0.01\n",
    "LEARNING_RATE = 0.01\n",
    "##动量因子为0.9\n",
    "MOMENTUM = 0.9\n",
    "##mlp隐藏单元\n",
    "mlp_hsize = 300\n",
    "##rnn隐藏单元\n",
    "rnn_hsize =300\n",
    "row = 0\n",
    "use_gpu = False\n",
    "h5file = \"D:/WorkSpace/Shell/datafeature/\"\n",
    "files = os.listdir(h5file)  # 得到文件夹下的所有文件名称\n",
    "files_len = len(files)\n",
    "channels = ['handfea', 'lable']\n",
    "savepath = \"D:/WorkSpace/Shell/MNN/result_new20/label/\"\n",
    "\n",
    "# 保存  训练测试结果\n",
    "def saveResult(testresult, loss_train, loss_test, acc, koldi, mnn):\n",
    "    np.savetxt('./result_new20/test_matrix/testresult' + koldi + '.txt', testresult)\n",
    "    np.savetxt('./result_new20/loss/loss_train' + koldi + '.txt', loss_train)\n",
    "    np.savetxt('./result_new20/acc/acc_' + koldi + '.txt', acc)\n",
    "    np.savetxt('./result_new20/loss/loss_test' + koldi + '.txt', loss_test)\n",
    "    torch.save(mnn, './net/net' + koldi + '.pkl')  # entire net\n",
    "\n",
    "\n",
    "# 训练MNN\n",
    "def mnnTrain(train_x, train_y, loss_all, mnn, loss_func,optimizer):\n",
    "    train_y_shape = train_y.shape[0]\n",
    "    train_y = train_y.view(train_y.shape[0]).type(torch.LongTensor)\n",
    "\n",
    "    if (use_gpu):\n",
    "        train_x, train_y = train_x.cuda(), train_y.cuda()\n",
    "    # mnn output\n",
    "    output = mnn(train_x.type(torch.FloatTensor))\n",
    "    loss = loss_func(output, train_y)\n",
    "\n",
    "    # cross entropy loss\n",
    "    loss_all = loss_all + loss\n",
    "    optimizer.zero_grad()  # clear gradients for this training step\n",
    "    loss.backward()  # backpropagation, compute gradients\n",
    "    optimizer.step()  # apply gradients\n",
    "\n",
    "\n",
    "# 画图  损失  准确率\n",
    "def plot_acc_loss(x1, x2, train_acc, loss_train, loss_test, foidi):\n",
    "    plt.plot(x1, train_acc, 'b.-', label='Train accuracy')\n",
    "    plt.title('accuracy vs epoches')\n",
    "    plt.xlabel('epoches')\n",
    "    plt.ylabel('accuracy')\n",
    "\n",
    "    plt.savefig(\"./result_new20/picture/accuracy\" + foidi + \".svg\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "    plt.plot(x2, loss_train, 'r.-', label=u'loss_train')\n",
    "    plt.title('loss vs epoches')\n",
    "    plt.xlabel('epoches')\n",
    "    plt.ylabel('loss')\n",
    "    plt.savefig(\"./result_new20/picture/train_loss\" + foidi + \".svg\")\n",
    "    plt.show()\n",
    "    plt.xlabel('epoches')\n",
    "    plt.plot(x2, loss_test, 'b.-', label=u'loss_test')\n",
    "    plt.title('loss vs epoches')\n",
    "    plt.ylabel('loss')\n",
    "    plt.savefig(\"./result_new20/picture/test_loss\" + foidi + \".svg\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def del_collect(del_var):\n",
    "\n",
    "    del del_var\n",
    "    gc.collect()\n",
    "\n",
    "\n",
    "def setDataset(h5file, train_index, type=0):\n",
    "    global eeg_data, labels\n",
    "    flag = 0\n",
    "    ##训练集\n",
    "    for filei in train_index:\n",
    "        with h5py.File(h5file + files[filei], 'r') as fileh5:\n",
    "            #    print(fileh5[channels[5]].value.shape)\n",
    "            if flag == 0:\n",
    "\n",
    "                eeg_data = torch.from_numpy(fileh5[channels[0]].value)\n",
    "                labels = torch.from_numpy(fileh5[channels[1]].value)\n",
    "                flag = 1\n",
    "            else:\n",
    "                eeg_data = torch.cat((eeg_data, torch.from_numpy(fileh5[channels[0]].value)),dim=0)\n",
    "                labels = torch.cat((labels, torch.from_numpy(fileh5[channels[1]].value)), dim=0)\n",
    "    if type == 1:\n",
    "        torch_dataset = Data.TensorDataset(eeg_data, labels.squeeze())\n",
    "        train_loader = Data.DataLoader(dataset=torch_dataset, batch_size=BATCH_SIZE, shuffle=False,num_workers=1)  ##num_workers是加载文件的核心数\n",
    "        return train_loader\n",
    "    else:\n",
    "        return eeg_data, labels.squeeze()\n",
    "\n",
    "##保存结果报告文件\n",
    "def save_to_file(file_name, contents):\n",
    "    fh = open(file_name, 'w')\n",
    "    fh.write(contents)\n",
    "    fh.close()\n",
    "\n",
    "\n",
    "def savePred(savepath, filename, label, pred):\n",
    "\n",
    "    with h5py.File(savepath + filename, 'w') as fileh5:\n",
    "        fileh5['label'] =label\n",
    "        fileh5['pred'] =label\n",
    "\n",
    "\n",
    "if __name__ =='__main__':\n",
    "\n",
    "\n",
    "    print(\"开始\")\n",
    "\n",
    "    for index in range(1, 21):\n",
    "        train_index, test_index = train_test_split(range(files_len), test_size=0.2, random_state=index)\n",
    "        save_list = []\n",
    "        save_list.append(train_index)\n",
    "        save_list.append(test_index)\n",
    "        save_to_file(\"D:/WorkSpace/Shell/MNN/list/list_\"+ str(index) +\".txt\", str(save_list))\n",
    "        mnn = MNNs()\n",
    "        optimizer = torch.optim.SGD(mnn.parameters(), lr=LEARNING_RATE)\n",
    "        loss_func = nn.CrossEntropyLoss()\n",
    "        if (use_gpu):\n",
    "            mnn = mnn.cuda()\n",
    "            loss_func = loss_func.cuda()\n",
    "\n",
    "        # 定义数组\n",
    "        Loss_list_train = []\n",
    "        Loss_list_test = []\n",
    "        Accuracy_list = []\n",
    "        Kappa = []\n",
    "        Loss_list2 = []\n",
    "        Accuracy_list2 = []\n",
    "        Matrix_all = []\n",
    "        global save_test_pred_all\n",
    "        global save_test_label_all\n",
    "\n",
    "        # 我这里迭代了80次，所以x的取值范围为(0，80)，然后再将每次相对应的准确率以及损失率附在x上\n",
    "        x1 = range(0, EPOCH)\n",
    "        x2 = range(0, EPOCH)\n",
    "        y1 = Accuracy_list\n",
    "        y2 = Loss_list_train\n",
    "        y3 = Loss_list_test\n",
    "        best_acc = 0\n",
    "\n",
    "        print(\"开始训练------\")\n",
    "        # 训练MNN网络\n",
    "\n",
    "        max_accuracy = 0\n",
    "        global save_test_pred_all\n",
    "        for epoch in range(EPOCH):\n",
    "            loss_all = 0\n",
    "            loss_test_all = 0\n",
    "            acc_train_all = 0\n",
    "            step_all = 0\n",
    "            test_step_all = 0\n",
    "\n",
    "            print(\"开始训练模型---------\")\n",
    "            train_part_len = len(train_index)//20 ##训练集划分長度\n",
    "            test_part_len = len(test_index)//8\n",
    "\n",
    "            train_part_len = len(train_index) // train_part_len\n",
    "            test_part_len = len(test_index) // test_part_len\n",
    "            for train_part in range(train_part_len):\n",
    "                if train_part == 0:\n",
    "                    train_part_index = train_index[train_part_len * train_part:train_part_len * (train_part + 1)]\n",
    "                elif train_part == (train_part_len-1):\n",
    "                    train_part_index = train_index[train_part_len * train_part:len(train_index)]\n",
    "                else:\n",
    "                    train_part_index = train_index[train_part_len * train_part:train_part_len * (train_part + 1)]\n",
    "                for step, (train_x, train_y) in enumerate(setDataset(h5file, train_part_index, type=1)):  # 设定训练数据\n",
    "\n",
    "                    train_y_shape = train_y.shape[0]\n",
    "                    train_y = train_y.view(train_y.shape[0])\n",
    "\n",
    "                    if (use_gpu):\n",
    "                        train_x, train_y = train_x.cuda(), train_y.cuda()\n",
    "                    # mnn output\n",
    "                    output = mnn(train_x.type(torch.FloatTensor))\n",
    "                    loss_train = loss_func(output, train_y.type(torch.LongTensor))\n",
    "\n",
    "\n",
    "                    # cross entropy loss\n",
    "\n",
    "                    optimizer.zero_grad()  # clear gradients for this training step\n",
    "                    loss_train.backward()  # backpropagation, compute gradients\n",
    "                    optimizer.step()  # apply gradients\n",
    "\n",
    "            print(\"训练模型完毕\")\n",
    "            test_step_all = 0\n",
    "            ##测试集切割\n",
    "\n",
    "            for test_part in range(test_part_len):\n",
    "                if test_part == 0:\n",
    "                    test_part_index = test_index[test_part_len * test_part:test_part_len * (test_part + 1)]\n",
    "                elif test_part == test_part_len-1:\n",
    "                    test_part_index = test_index[test_part_len * test_part:len(test_index)]\n",
    "                else:\n",
    "                    test_part_index = test_index[test_part_len * test_part:test_part_len * (test_part + 1)]\n",
    "\n",
    "                for step, (test_x, test_y) in enumerate(setDataset(h5file, test_part_index, type=1)):  # 设定训练数据\n",
    "\n",
    "                    if step == 0:\n",
    "\n",
    "                        test_label_all = deepcopy(test_y)\n",
    "                    else:\n",
    "                        test_label_all = torch.cat((test_label_all, test_y), dim=0)\n",
    "                    test_y = test_y.view(test_y.shape[0])\n",
    "\n",
    "                    # mnn output\n",
    "                    output = mnn(test_x.type(torch.FloatTensor))\n",
    "                    test_pred_y = torch.max(F.softmax(output), 1)[1]\n",
    "\n",
    "\n",
    "                    if step == 0:\n",
    "                        test_pred_all = deepcopy(test_pred_y)\n",
    "                    else:\n",
    "                        test_pred_all = torch.cat((test_pred_all, test_pred_y), dim=0)\n",
    "\n",
    "                    loss_test = loss_func(output, test_y.type(torch.LongTensor))\n",
    "                    # cross entropy loss\n",
    "                    loss_test_all = loss_test_all + loss_test\n",
    "                test_step_all = step + 1 + test_step_all\n",
    "\n",
    "            # #测试集\n",
    "\n",
    "            test_accuracy = accuracy_score(test_label_all.numpy().squeeze(), test_pred_all.numpy().squeeze())\n",
    "            loss_test_avg = loss_test_all / test_step_all\n",
    "            Loss_list_test.append(loss_test_avg)\n",
    "\n",
    "\n",
    "            Accuracy_list.append(test_accuracy)\n",
    "            # accuracy = sum(test_labels1 == pred_y)/ test_labels.numpy().squeeze().size\n",
    "            print(str(index) + '_Epoch: ', epoch + 1,\n",
    "                '| test loss: %.4f' % loss_test_avg, '| test accuracy: %.4f' % test_accuracy)\n",
    "\n",
    "            gc.collect()\n",
    "            torch.cuda.empty_cache()\n",
    "            Matrix_all.append(cm(np.array(test_label_all).reshape(-1).squeeze(), np.array(test_pred_all).reshape(-1).squeeze()))\n",
    "            Kappa.append(kappa(cm(np.array(test_label_all).reshape(-1).squeeze(), np.array(test_pred_all).reshape(-1).squeeze())))\n",
    "\n",
    "            if epoch!=50:\n",
    "\n",
    "                del test_label_all,test_pred_all\n",
    "                gc.collect()\n",
    "                torch.cuda.empty_cache()\n",
    "            else:\n",
    "                save_test_pred_all = test_label_all\n",
    "                save_test_label_all = test_pred_all\n",
    "                del test_label_all,test_pred_all\n",
    "                gc.collect()\n",
    "                torch.cuda.empty_cache()\n",
    "\n",
    "        # #混淆矩阵\n",
    "\n",
    "        print(\"结束训练网络-------\")\n",
    "\n",
    "        for index in test_index:\n",
    "            test_x, test_y = setDataset(h5file, [index], type=0)\n",
    "            # mnn output\n",
    "            output = mnn(test_x.type(torch.FloatTensor))\n",
    "            test_pred_y = torch.max(F.softmax(output), 1)[1]\n",
    "            savePred(savepath, files, test_y, test_pred_y)\n",
    "\n",
    "\n",
    "        result1 = np.array(Matrix_all).reshape(-1, 25)\n",
    "        # result4 = np.array(Loss_list_test)\n",
    "        result2 = np.array(Loss_list_train)\n",
    "        result3 = np.array(Loss_list_test)\n",
    "        result4 = np.array(Accuracy_list)\n",
    "        saveResult(result1, result2, result3, result4, \"_\" + str(index).zfill(2), mnn)\n",
    "        # 画图及保存\n",
    "        plot_acc_loss(x1, x2, y1, y2, y3, \"_\" + str(index).zfill(2))\n",
    "        result5 = np.array(Kappa)\n",
    "        cm_plot(np.array(save_test_pred_all).reshape(-1).squeeze(), np.array(save_test_label_all).reshape(-1).squeeze(),\n",
    "                \"_\" + str(index))\n",
    "        np.savetxt('./result_new20/kappa/kappa_' + str(index) + '.txt', result5)\n",
    "        if 'save_test_pred_all' in vars():\n",
    "            del save_test_pred_all,save_test_label_all\n",
    "            gc.collect()\n",
    "        torch.cuda.empty_cache()\n",
    "        gc.collect()\n",
    "    print(\"结束\")\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "pytorch_gpu",
   "language": "python",
   "display_name": "pytorch_gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}