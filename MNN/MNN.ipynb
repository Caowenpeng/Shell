{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "[WinError 1455] 页面文件太小，无法完成操作。 Error loading \"D:\\Software\\Anaconda\\envs\\pytorch_gpu\\lib\\site-packages\\torch\\lib\\caffe2_detectron_ops_gpu.dll\" or one of its dependencies.",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mOSError\u001B[0m                                   Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-1-1977a1801889>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mos\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      2\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0msys\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 3\u001B[1;33m \u001B[1;32mimport\u001B[0m \u001B[0mtorch\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      4\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mtorch\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mnn\u001B[0m \u001B[1;32mas\u001B[0m \u001B[0mnn\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      5\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mtorch\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mnn\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mfunctional\u001B[0m \u001B[1;32mas\u001B[0m \u001B[0mF\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mD:\\Software\\Anaconda\\envs\\pytorch_gpu\\lib\\site-packages\\torch\\__init__.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m    114\u001B[0m                 \u001B[0merr\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mctypes\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mWinError\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mlast_error\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    115\u001B[0m                 \u001B[0merr\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mstrerror\u001B[0m \u001B[1;33m+=\u001B[0m \u001B[1;34m' Error loading \"{}\" or one of its dependencies.'\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mformat\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mdll\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 116\u001B[1;33m                 \u001B[1;32mraise\u001B[0m \u001B[0merr\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    117\u001B[0m             \u001B[1;32melif\u001B[0m \u001B[0mres\u001B[0m \u001B[1;32mis\u001B[0m \u001B[1;32mnot\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    118\u001B[0m                 \u001B[0mis_loaded\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;32mTrue\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mOSError\u001B[0m: [WinError 1455] 页面文件太小，无法完成操作。 Error loading \"D:\\Software\\Anaconda\\envs\\pytorch_gpu\\lib\\site-packages\\torch\\lib\\caffe2_detectron_ops_gpu.dll\" or one of its dependencies."
     ]
    }
   ],
   "source": [
    "\n",
    "import os\n",
    "import sys\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as Data\n",
    "import torch.optim as optim\n",
    "from MNN import *\n",
    "import pyedflib\n",
    "import numpy as np\n",
    "import h5py\n",
    "from torch.autograd import Variable\n",
    "import math\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.metrics import confusion_matrix as cm\n",
    "import  matplotlib.pyplot as plt\n",
    "import random\n",
    "import copy\n",
    "from sklearn.model_selection import KFold\n",
    "import gc\n",
    "from ResultCode import cm_plot\n",
    "\n",
    "##迭代次数为50\n",
    "EPOCH = 80\n",
    "#batch size 为500\n",
    "BATCH_SIZE = 500\n",
    "##学习率为0.01\n",
    "LEARNING_RATE = 0.01\n",
    "##动量因子为0.9\n",
    "MOMENTUM = 0.9\n",
    "##mlp隐藏单元\n",
    "mlp_hsize = 300\n",
    "##rnn隐藏单元\n",
    "rnn_hsize =300\n",
    "row = 0\n",
    "use_gpu = False\n",
    "h5file = \"D:/WorkSpace/Shell/datafeature/\"\n",
    "tensor_data_path =\"D:/WorkSpace/Shell/data/h5data/\"\n",
    "files= os.listdir(h5file) #得到文件夹下的所有文件名称\n",
    "files_len = len(files)\n",
    "channels = ['ECG','EMG','EOG-R','EOG-L','O2-A1','C4-A1','F4-A1']\n",
    "Max_acc = []\n",
    "\n",
    "#保存  训练测试结果\n",
    "def saveResult(testresult,loss_train,loss_test,acc,koldi,mnn):\n",
    "    np.savetxt('./result_new20/test_matrix/testresult'+koldi+'.txt',testresult)\n",
    "    np.savetxt('./result_new20/loss/loss_train'+koldi+'.txt',loss_train)\n",
    "    np.savetxt('./result_new20/acc/acc_'+koldi+'.txt',acc)\n",
    "    np.savetxt('./result_new20/loss/loss_test'+koldi+'.txt',loss_test)\n",
    "    torch.save(mnn,'/net/net'+koldi+'.pkl')  #entire net\n",
    "\n",
    "#训练MNN\n",
    "def mnnTrain(train_x,train_y,loss_all,mnn,loss_func):\n",
    "    train_y_shape = train_y.shape[0]\n",
    "    train_y=train_y.view(train_y.shape[0]).type(torch.LongTensor)\n",
    "\n",
    "    if(use_gpu):\n",
    "        train_x,train_y = train_x.cuda(),train_y.cuda()\n",
    "    # mnn output\n",
    "    output = mnn(train_x.type(torch.FloatTensor))\n",
    "    loss = loss_func(output, train_y)\n",
    "\n",
    "    # cross entropy loss\n",
    "    loss_all = loss_all + loss\n",
    "    optimizer.zero_grad()           # clear gradients for this training step\n",
    "    loss.backward()                 # backpropagation, compute gradients\n",
    "    optimizer.step()                # apply gradients\n",
    "#画图  损失  准确率\n",
    "def plot_acc_loss(x1,x2,train_acc,loss_train,loss_test,koidi):\n",
    "\n",
    "    plt.plot(x1, train_acc, 'b.-', label = 'Train accuracy')\n",
    "    plt.title('accuracy vs epoches')\n",
    "    plt.xlabel('epoches')\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.legend([\"Test accuracy\",\"Train accuracy\"])\n",
    "    plt.savefig(\"./result_new20/picture/accuracy\"+koidi+\".jpg\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "    plt.subplot(2,1,1)\n",
    "    plt.plot(x2, loss_train, 'r.-', label = u'loss_train')\n",
    "    plt.subplot(2,1,1)\n",
    "    plt.plot(x2, loss_test, 'b.-', label = u'loss_test')\n",
    "    plt.title('loss vs epoches')\n",
    "    plt.ylabel('loss')\n",
    "    plt.savefig(\"./result_new20/picture/loss\"+koidi+\".jpg\")\n",
    "    plt.show()\n",
    "\n",
    "def del_collect(del_var):\n",
    "    del del_var\n",
    "    gc.collect()\n",
    "\n",
    "\n",
    "\n",
    "def Set_Dataset(h5file,train_index,type = 0):\n",
    "    global eeg_data,labels\n",
    "    flag=0\n",
    "    ##训练集\n",
    "    for filei in train_index:\n",
    "        fileh5 = h5py.File(h5file+files[filei], 'r')\n",
    "#    print(fileh5[channels[5]].value.shape)\n",
    "\n",
    "    #短时傅里叶变换  n_fft=5s*采样率  窗口重叠为70%即窗口滑动hop_length=n_fft*30%\n",
    "    ##返回值为一个tensor,其中第一个维度为输入数据的batch size，\n",
    "    # 第二个维度为STFT应用的频数，\n",
    "    # 第三个维度为帧总数，\n",
    "    # 最后一个维度包含了返回的复数值中的实部和虚部部分\n",
    "    #拼接文件的数据\n",
    "    # if filei == 0:\n",
    "    #     stft_data = torch.stft(torch.from_numpy(fileh5[channels[5]].value),n_fft=5*sample_rate,hop_length=int(5*sample_rate*0.25))\n",
    "    #     labels = torch.from_numpy(fileh5[\"labels\"].value)\n",
    "    # else:\n",
    "    #     stft_data = torch.cat((stft_data,torch.stft(torch.from_numpy(fileh5[channels[5]].value),n_fft=5*sample_rate,hop_length=int(5*sample_rate*0.25))),dim = 0)\n",
    "    #     labels = torch.cat((labels,torch.from_numpy(fileh5[\"labels\"].value)),dim = 0)\n",
    "    #\n",
    "        if flag == 0:\n",
    "            eeg_data_channel1 = torch.from_numpy(fileh5[\"F4-A1\"].value)\n",
    "            eeg_data_channel2 = torch.from_numpy(fileh5[\"EOG-L\"].value)\n",
    "            eeg_data = torch.cat((eeg_data_channel1,eeg_data_channel2),dim = 1)\n",
    "            labels = torch.from_numpy(fileh5[\"labels\"].value)\n",
    "            flag=1\n",
    "\n",
    "        else:\n",
    "            eeg_data_channel1 = torch.from_numpy(fileh5[\"F4-A1\"].value)\n",
    "            eeg_data_channel2 = torch.from_numpy(fileh5[\"EOG-L\"].value)\n",
    "            eeg_data_new = torch.cat((eeg_data_channel1,eeg_data_channel2),dim = 1)\n",
    "            eeg_data = torch.cat((eeg_data,eeg_data_new),dim = 0)\n",
    "            labels = torch.cat((labels,torch.from_numpy(fileh5[\"labels\"].value)),dim = 0)\n",
    "\n",
    "    if type == 1:\n",
    "        torch_dataset = Data.TensorDataset(eeg_data,labels.squeeze())\n",
    "        train_loader = Data.DataLoader(dataset=torch_dataset, batch_size=BATCH_SIZE, shuffle=True,num_workers=1)##num_workers是加载文件的核心数\n",
    "        return train_loader\n",
    "    else:\n",
    "        return eeg_data,labels.squeeze()\n",
    "\n",
    "##提取训练数据\n",
    "Sam=np.array(range(files_len)) #\n",
    "New_sam=KFold(n_splits=5)\n",
    "foldi = 0\n",
    "\n",
    "print(\"开始\")\n",
    "\n",
    "for train_index,test_index in New_sam.split(Sam):\n",
    "    \n",
    "    foldi = foldi + 1\n",
    "\n",
    "\n",
    "    print(\"读取测试数据开始---------\")\n",
    "\n",
    "    test_eeg_data,test_labels=Set_Dataset(h5file,test_index,type=0)\n",
    "\n",
    "    mnn = MNNs()\n",
    "    optimizer = torch.optim.SGD(mnn.parameters(),lr=LEARNING_RATE)\n",
    "    loss_func = nn.CrossEntropyLoss()\n",
    "    if(use_gpu):\n",
    "        mnn = mnn.cuda()\n",
    "        loss_func = loss_func.cuda()\n",
    "\n",
    "    #定义数组\n",
    "    Loss_list_train = []\n",
    "    Loss_list_test = []\n",
    "    Accuracy_list = []\n",
    "    Kappa = []\n",
    "    Loss_list2 = []\n",
    "    Accuracy_list2 = []\n",
    "\n",
    "    #我这里迭代了80次，所以x的取值范围为(0，80)，然后再将每次相对应的准确率以及损失率附在x上\n",
    "    x1 = range(0, EPOCH)\n",
    "    x2 = range(0, EPOCH)\n",
    "    y1 = Accuracy_list\n",
    "    y2 = Loss_list_train\n",
    "    y3 = Loss_list_test\n",
    "    best_acc = 0\n",
    "\n",
    "    print(\"开始训练------\")\n",
    "    #训练MNN网络\n",
    "\n",
    "    max_accuracy = 0\n",
    "\n",
    "    for epoch in range(EPOCH):\n",
    "        loss_all = 0\n",
    "        loss_test_all = 0\n",
    "        acc_train_all = 0\n",
    "        step_all = 0\n",
    "        print(\"开始训练模型---------\")\n",
    "        train_part_len = len(train_index)//5\n",
    "        for train_part in range(5):\n",
    "            if train_part == 0:\n",
    "                train_part_index = train_index[train_part_len*train_part:train_part_len*(train_part+1)]\n",
    "            elif train_part == 4:\n",
    "                train_part_index = train_index[train_part_len*train_part:len(train_index)]\n",
    "            else:\n",
    "                train_part_index = train_index[train_part_len*train_part:train_part_len*(train_part+1)]\n",
    "            train_loader = Set_Dataset(h5file,train_part_index,type=1)\n",
    "            for step, (train_x, train_y) in enumerate(train_loader):  #设定训练数据\n",
    "                train_y_shape = train_y.shape[0]\n",
    "                train_y=train_y.view(train_y.shape[0])\n",
    "\n",
    "                if(use_gpu):\n",
    "                    train_x,train_y = train_x.cuda(),train_y.cuda()\n",
    "                # mnn output\n",
    "                output = mnn(train_x.type(torch.FloatTensor))\n",
    "                loss_train = loss_func(output, train_y.type(torch.LongTensor))\n",
    "                train_pred_y = torch.max(F.softmax(output), 1)[1].numpy().squeeze()\n",
    "                # cross entropy loss\n",
    "                loss_all = loss_all + loss_train\n",
    "                optimizer.zero_grad()           # clear gradients for this training step\n",
    "                loss_train.backward()                 # backpropagation, compute gradients\n",
    "                optimizer.step()                # apply gradients\n",
    "            step_all = step + 1 + step_all\n",
    "        print(\"训练模型完毕\")\n",
    "        #准确率\n",
    "        train_accuracy = accuracy_score(train_y,train_pred_y)\n",
    "        loss_all_avg = loss_all/(step_all)\n",
    "        Loss_list_train.append(loss_all_avg)\n",
    "\n",
    "\n",
    "        # #测试集\n",
    "        test_output = mnn(test_eeg_data.type(torch.FloatTensor))\n",
    "        loss_test = loss_func(test_output,test_labels.type(torch.LongTensor))\n",
    "        Loss_list_test.append(loss_test)\n",
    "        pred_y = torch.max(test_output, 1)[1].squeeze()\n",
    "\n",
    "        mnn(test_eeg_data.type(torch.FloatTensor))\n",
    "\n",
    "        # #混淆矩阵\n",
    "        matrix = cm(test_labels.numpy().squeeze(),pred_y)\n",
    "        # #准确率\n",
    "        accuracy = accuracy_score(test_labels.numpy().squeeze(),pred_y)\n",
    "        Accuracy_list.append(accuracy)\n",
    "\n",
    "        #accuracy = sum(test_labels1 == pred_y)/ test_labels.numpy().squeeze().size\n",
    "        print(str(foldi)+'_Epoch: ', epoch+1, '| train loss: %.4f' % loss_all_avg,'| train accuracy: %.4f' %train_accuracy,\n",
    "          '| test loss: %.4f' % loss_test,'| test accuracy: %.4f' % accuracy)\n",
    "\n",
    "        gc.collect()\n",
    "\n",
    "    # #混淆矩阵\n",
    "    matrix = cm(test_labels.numpy().squeeze(),pred_y.numpy().squeeze())\n",
    "\n",
    "\n",
    "    # Max_acc.append(accuracy)\n",
    "\n",
    "    print(\"结束训练网络-------\")\n",
    "    #保存\n",
    "    result1 = np.array(matrix)\n",
    "        #result4 = np.array(Loss_list_test)\n",
    "    result2 = np.array(Loss_list_train)\n",
    "    result3 = np.array(Loss_list_test)\n",
    "    result4 = np.array(Accuracy_list)\n",
    "    saveResult(result1,result2,result3,result4,\"_\"+str(foldi).zfill(2),mnn)\n",
    "    #画图及保存\n",
    "    plot_acc_loss(x1,x2,y1,y2,y3,\"_\"+str(foldi).zfill(2))\n",
    "    Kappa.append(cm_plot(test_labels.numpy().squeeze(),pred_y,\"_\"+str(foldi)))\n",
    "    result5 = np.array(Kappa)\n",
    "    np.savetxt('./result_new20/kappa/kappa_'+str(foldi)+'.txt',result5)\n",
    "    torch.cuda.empty_cache() \n",
    "print(\"结束\")\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "pytorch_gpu",
   "language": "python",
   "display_name": "pytorch_gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}